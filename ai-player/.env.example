# Ollama Configuration
OLLAMA_HOST=localhost
OLLAMA_PORT=11434
OLLAMA_MODEL=gemma2:270m

# AI Service Configuration
AI_TIMEOUT=10000
AI_TEMPERATURE=0.7
FALLBACK_TO_HEURISTIC=true
ENABLE_REASONING_LOG=true

# Server Configuration
PORT=3001
NODE_ENV=production

# Logging
LOG_LEVEL=info

# Security
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001

# Optional: Custom model parameters
# AI_MAX_TOKENS=512
# AI_TOP_P=0.9
# AI_TOP_K=40